{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c99229d-153e-4a0f-b81c-e23096dda5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import error: No module named 'triton'\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from huggingface_hub import hf_hub_download\n",
    "from generator import Generator, Segment, load_csm_1b, generate_streaming_audio\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42dd9a91-90fa-4805-827c-f2f3f7613058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSM-1B model...\n",
      "Model compilation complete. Creating generator...\n",
      "Starting warmup sequence...\n",
      "Creating diverse audio contexts...\n",
      "Forcing compilation of critical components...\n",
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsinzore/csm-streaming/venvcsm.streaming/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running final generation with exact same setup as a real request...\n",
      "Starting audio generation for: 'This is the final warmup that exactly matches a re...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsinzore/csm-streaming/venvcsm.streaming/lib/python3.10/site-packages/torch/amp/autocast_mode.py:283: UserWarning: In CPU autocast, but the target dtype is not supported. Disabling autocast.\n",
      "CPU Autocast only supports dtype of torch.bfloat16, torch.float16 currently.\n",
      "  warnings.warn(error_message)\n",
      "/Users/benjaminsinzore/csm-streaming/venvcsm.streaming/lib/python3.10/site-packages/torch/amp/autocast_mode.py:283: UserWarning: In CPU autocast, but the target dtype is not supported. Disabling autocast.\n",
      "CPU Autocast only supports dtype of torch.bfloat16, torch.float16 currently.\n",
      "  warnings.warn(error_message)\n",
      "/Users/benjaminsinzore/csm-streaming/venvcsm.streaming/lib/python3.10/site-packages/torch/amp/autocast_mode.py:283: UserWarning: In CPU autocast, but the target dtype is not supported. Disabling autocast.\n",
      "CPU Autocast only supports dtype of torch.bfloat16, torch.float16 currently.\n",
      "  warnings.warn(error_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First chunk latency: 27907.7ms\n",
      "Total time: 51.70s\n",
      "Generated 58 frames (4.64s of audio)\n",
      "Real-time factor: 11.141x (target: <1.0)\n",
      "\n",
      "==================================================\n",
      "AUDIO GENERATION PERFORMANCE METRICS\n",
      "==================================================\n",
      "First chunk latency: 27907.7ms\n",
      "Total generation time: 52.37s\n",
      "Audio duration: 4.64s\n",
      "Real-time factor (RTF): 11.286x (target: <1.0)\n",
      "Number of chunks: 3\n",
      "Average chunk size: 1546.7ms\n",
      "Average inter-chunk latency: 11973.6ms\n",
      "Min/Max inter-chunk latency: 11920.5ms / 12026.7ms\n",
      "Chunks per second: 0.06\n",
      "Output file: warmup_final.wav\n",
      "==================================================\n",
      "Warmup complete.\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "generator = load_csm_1b(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54b932b-e850-48cb-b1ed-47f3df06183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling from 24000Hz to 44100Hz for playback\n",
      "Starting audio generation for: 'Hello, I'm Owili Benjamin Sinzore, and this is str...'\n",
      "First chunk latency: 12624.4ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsinzore/csm-streaming/venvcsm.streaming/lib/python3.10/site-packages/torch/amp/autocast_mode.py:283: UserWarning: In CPU autocast, but the target dtype is not supported. Disabling autocast.\n",
      "CPU Autocast only supports dtype of torch.bfloat16, torch.float16 currently.\n",
      "  warnings.warn(error_message)\n",
      "/Users/benjaminsinzore/csm-streaming/venvcsm.streaming/lib/python3.10/site-packages/torch/amp/autocast_mode.py:283: UserWarning: In CPU autocast, but the target dtype is not supported. Disabling autocast.\n",
      "CPU Autocast only supports dtype of torch.bfloat16, torch.float16 currently.\n",
      "  warnings.warn(error_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 45.97s\n",
      "Generated 70 frames (5.60s of audio)\n",
      "Real-time factor: 8.209x (target: <1.0)\n",
      "Waiting for audio playback to complete...\n"
     ]
    }
   ],
   "source": [
    "# Generate audio with streaming and real-time playback\n",
    "generate_streaming_audio(\n",
    "    generator=generator,\n",
    "    text=\"Hello, I'm Owili Benjamin Sinzore, and this is streaming audio generation in action!\",\n",
    "    speaker=0,\n",
    "    context=[],  # No context needed for basic generation\n",
    "    output_file=\"streaming_audio.wav\",\n",
    "    play_audio=True  # Enable real-time playback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f638fb-fc7a-49b2-b095-5afe25f904cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -c \"import torch; print(torch.backends.mps.is_available())\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbcb724-4d38-4f5a-b933-245bc7a5b5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSM-Streaming Environment",
   "language": "python",
   "name": "venvcsm.streaming"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
